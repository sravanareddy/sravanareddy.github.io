<html>
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="Description" content="Sravana Reddy is a postdoctoral fellow in computational linguistics at the Neukom Institute.">
<title>Sravana Reddy</title>
<link rel="stylesheet" href="cs.css" type="text/css" />
</head>
<body>

<script src="jquery.js"></script>
<script src="dynamic.js"></script>

<div id="main">

  <!-- Header -->
  
 
  <h1>
Sravana Reddy 
    (<img src="sravana-name.jpg">)
<br>  <img src="sravana-email.gif" alt="firstname at cs period dartmouth period edu"/>
</h1>

  
  <div id="header">

    
  I am a
<a href="http://neukom.dartmouth.edu/programs/neukom_fellows14.html"
    target="_blank">Neukom Postdoctoral Fellow</a> at <a href="http://www.dartmouth.edu/" target="_blank">Dartmouth College</a>, affiliated with <a href="http://www.dartmouth.edu/~linguist/" target="_blank">Linguistics</a> and <a href="http://www.cs.dartmouth.edu/" target="_blank">Computer Science</a>. My research is centered around the unsupervised learning
  of natural language structure.  
  I graduated from 
  <a href="http://www.uchicago.edu/" target="_blank">The University of
  Chicago</a>.</p>

</div>

   


   <hr width="80%" />

<center>
<a class="breadcrumbs" href="#research">Research</a>
&nbsp;&nbsp;::&nbsp;&nbsp;
<a class="breadcrumbs" href="#teaching">Teaching</a>
&nbsp;&nbsp;::&nbsp;&nbsp;
<a class="breadcrumbs" href="#edu">Experience</a>
</center>


<!-- Research -->

<a name="research"></a><h2>Research</h2>

<h3 id="conf">Publications</h3>

<ul>

  <p><li>Sravana Reddy and <a
  href="http://www.dartmouth.edu/~jstanford/" target="_blank">James
  Stanford</a> (2015). <u>Toward completely automated vowel extraction:
Introducing DARLA</u>. To appear in <i>Linguistics Vanguard</i>.<br>
  <span class="breadcrumbs">
  [<a href="papers/darla_naacl.pdf" target="_blank">paper</a>]
  [<a href="javascript:exp_coll('abstract11');">abstract</a>]
  [<a href="javascript:exp_coll('bib11');">bib</a>]
  </span>
<div id="abstract11" style="display:none">
  <blockquote>
  <h4>Abstract</h4><p>
Automatic Speech Recognition (ASR) is reaching further and further
  into everyday life with Apple's Siri, Google voice search, automated
  telephone information systems, dictation devices, closed captioning,
  and other applications. Along with such advances in speech
  technology, sociolinguists have been considering new methods for
  alignment and vowel formant extraction, including techniques like
  the Penn Aligner (Yuan and Liberman, 2008) and the FAVE automated
  vowel extraction program (Evanini et al., 2009, Rosenfelder et al.,
  2011). With humans transcribing audio recordings into sen- tences,
  these semi-automated methods can produce effective vowel formant
  measure- ments (Labov et al., 2013). But as the quality of ASR
  improves, sociolinguistics may be on the brink of another
  transformative technology: large-scale, completely automated vowel
  extraction without any need for human transcription. It would then
  be possible to quickly extract vowels from virtually limitless hours
  of recordings, such as YouTube, publicly available audio/video
  archives, and large-scale personal interviews or streaming
  video. How far away is this transformative moment? In this article,
  we introduce a fully automated program called DARLA (short for
  "Dartmouth Linguistic Automation,"
  <a href="http://darla.dartmouth.edu"
  target"_blank">http://darla.dartmouth.edu</a>),
  which automatically generates transcriptions with ASR and extracts vowels using FAVE. Users simply upload an audio recording of speech, and DARLA produces vowel plots, a table of vowel formants, and probabilities of the phonetic environments for each token. In this paper, we describe DARLA and explore its sociolinguistic applications. We test the system on a dataset of the US Southern Shift and compare the results with semi-automated methods.
  </blockquote>
</div>

<div id="bib11" style="display:none">
  <blockquote>
   <h4>.bib</h4><p>
  <pre>
@article{ReddyStanfordB:2015,
  title = {Toward completely automated vowel extraction: Introducing DARLA},
  author = {Sravana Reddy and James N. Stanford},
  journal = {Linguistics Vanguard (to appear)},
  year = {2015},
}
</pre>
  </blockquote>
</div>
 
<p><li>Sravana Reddy and <a
  href="http://www.dartmouth.edu/~jstanford/" target="_blank">James
  Stanford</a> (2015). <u>A Web Application for Automated Dialect
  Analysis</u>. In <i>Proceedings of NAACL</i>.<br>
  <span class="breadcrumbs">
  [<a href="papers/darla_naacl.pdf" target="_blank">paper</a>]
  [<a href="javascript:exp_coll('abstract10');">abstract</a>]
  [<a href="javascript:exp_coll('bib10');">bib</a>]
  [<a href="http://darla.dartmouth.edu" target="_blank">website</a>]
  </span>
<div id="abstract10" style="display:none">
  <blockquote>
  <h4>Abstract</h4><p>
Sociolinguists are regularly faced with the task of measuring phonetic features from speech, which involves manually transcribing audio recordings -- a major bottleneck to analyzing large collections of data. We harness automatic speech recognition to build an online end-to-end web application where users upload untranscribed speech collections and receive formant measurements of the vowels in their data. We demonstrate this tool by using it to automatically analyze President Barack Obama’s vowel pronunciations.
</blockquote>
</div>

<div id="bib10" style="display:none">
  <blockquote>
   <h4>.bib</h4><p>
  <pre>
@inproceedings{ReddyStanfordA:2015,
  title = {A Web Application for Automated Dialect Analysis},
  author = {Sravana Reddy and James N. Stanford},
  booktitle = {NAACL (demos)},
  year = {2015},
}
</pre>
  </blockquote>
</div>

</p>


<p><li>Sravana Reddy and <a href="http://www.isi.edu/~knight" target="_blank">Kevin Knight</a>
  (2012).
<u>Decoding Running Key Ciphers</u>. 
In <i>Proceedings of ACL</i>.<br>
<span class="breadcrumbs">
  [<a href="papers/runkey_acl.pdf" target="_blank">paper</a>]
  [<a href="javascript:exp_coll('abstract8');">abstract</a>]
  [<a href="javascript:exp_coll('bib8');">bib</a>]
  </span>
<div id="abstract8" style="display:none">
  <blockquote>
  <h4>Abstract</h4><p>
There has been recent interest in the problem of decoding letter substitution ciphers using techniques inspired by natural language processing. We consider a different type of classical encoding scheme known as the running key cipher, and propose a search solution using Gibbs sampling with a word language model. We evaluate our method on synthetic ciphertexts of different lengths, and find that it outperforms previous work that employs Viterbi 
decoding with character-based models. 
</blockquote>
</div>

<div id="bib8" style="display:none">
  <blockquote>
   <h4>.bib</h4><p>
  <pre>
@inproceedings{ReddyKnight:2012,
  title = {Decoding Running Key Ciphers},
  author = {Sravana Reddy and Kevin Knight},
  booktitle = {ACL},
  year = {2012},
}
</pre>
  </blockquote>
</div>

</p>

<p><li><a href="http://people.cs.uchicago.edu/~wax" target="_blank">Sonjia Waxmonsky</a> 
and Sravana Reddy 
(2012).
<u>G2P Conversion of Proper Names Using Word Origin Information</u>.
In <i>Proceedings of NAACL</i>.<br>
<span class="breadcrumbs">
[<a href="papers/wordoriging2p_naacl.pdf" target="_blank">paper</a>]
[<a href="javascript:exp_coll('abstract7');">abstract</a>]
[<a href="javascript:exp_coll('bib7');">bib</a>]
[<a href="http://people.cs.uchicago.edu/~wax/wordorigin/" target="_blank">word origin data</a>]
[<a href="slides/wordoriging2p_naacl_poster.pdf" target="_blank">poster</a>]
</span>

<div id="abstract7" style="display:none">
  <blockquote>
  <h4>Abstract</h4><p>
Motivated by the fact that the pronunciation of a name may be
influenced by its language of origin,  we present methods to improve
pronunciation prediction of proper names using
word origin information. 
We train grapheme-to-phoneme (G2P) models on language-specific data
sets and interpolate the outputs. 
We perform experiments on US personal surnames, a data set where word origin variation 
occurs naturally.
Our methods can be used with any G2P algorithm that outputs
posterior probabilities of phoneme sequences for a given word.
</blockquote>
</div>

<div id="bib7" style="display:none">
  <blockquote>
   <h4>.bib</h4><p>
  <pre>
@inproceedings{WaxmonskyReddy:2012,
  title = {G2{P} Conversion of Proper Names Using Word Origin Information},
  author = {Sonjia Waxmonsky and Sravana Reddy},
  booktitle = {NAACL},
  year = {2012},
}
</pre>
  </blockquote>
</div>
</p>

  <li>
<p>Sravana Reddy and <a href="http://egouvea.users.sourceforge.net" target="_blank">Evandro Gouv&ecirc;a</a>
(2011). 
<u>Learning from Mistakes: Expanding Pronunciation Lexicons Using Word Recognition Errors</u>. 
In <i>Proceedings of Interspeech</i>.<br>

<span class="breadcrumbs">
[<a href="papers/lfm_interspeech.pdf" target="_blank">paper</a>]
[<a href="javascript:exp_coll('abstract6');">abstract</a>]
[<a href="javascript:exp_coll('bib6');">bib</a>]
[<a href="slides/lfm_interspeech_slides.pdf" target="_blank">slides</a>]
</span>

<div id="abstract6" style="display:none">
  <blockquote>
  <h4>Abstract</h4><p>
We introduce the problem of learning pronunciations of out-of-vocabulary words from word recognition mistakes made by an automatic speech recognition (ASR) system. This question is especially relevant in cases where the  ASR engine is a black box -- meaning that the only acoustic cues about the speech data come from the word recognition outputs. This paper presents an expectation maximization approach to inferring pronunciations from ASR word recognition hypotheses, which outperforms pronunciation estimates of a state of the art grapheme-to-phoneme system.</blockquote>
</div>

<div id="bib6" style="display:none">
  <blockquote>
   <h4>.bib</h4><p>
  <pre>
@inproceedings{ReddyGouvea:2011c,
  title = {Learning from Mistakes: Expanding Pronunciation Lexicons Using Word Recognition Errors},
  author = {Sravana Reddy and Evandro Gouv\^{e}a},
  booktitle = {Interspeech},
  year = {2011},
}
</pre>
  </blockquote>
</div>
</p>

<li>
<p>
Sravana Reddy and <a href="http://www.isi.edu/~knight" target="_blank">Kevin Knight</a>
(2011). 
<u>Unsupervised Discovery of Rhyme Schemes</u>. 
In <i>Proceedings of ACL</i>. <br>
<span class="breadcrumbs">
[<a href="papers/rhymes_acl.pdf" target="_blank">paper</a>]
[<a href="javascript:exp_coll('abstract5');">abstract</a>]
[<a href="javascript:exp_coll('bib5');">bib</a>]
[<a href="slides/rhymes_acl_slides.pdf" target="_blank">slides</a>]
[<a href="https://github.com/sravanareddy/rhymedata" target="_blank">rhyming corpus</a>]
[<a href="https://github.com/sravanareddy/rhymediscovery" target="_blank">code</a>]
</span>

<div id="abstract5" style="display:none">
  <blockquote>
  <h4>Abstract</h4><p>
  This paper describes an unsupervised, language-independent model for finding rhyme schemes in poetry, using no prior knowledge about rhyme or pronunciation.
</blockquote>
</div>
<div id="bib5" style="display:none">
   <blockquote>
   <h4>.bib</h4><p>
  <pre>
@inproceedings{ReddyKnight:2011a,
  title = {Unsupervised Discovery of Rhyme Schemes},
  author = {Sravana Reddy and Kevin Knight},
  booktitle = {ACL},
  year = {2011},
}
</pre>
   </blockquote>
</div>
</p>

  
<li>
<p>
Sravana Reddy and <a href="http://www.isi.edu/~knight" target="_blank">Kevin Knight</a>
(2011).
<u>What We Know About The Voynich Manuscript</u>. 
In <i>Proceedings of the ACL Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities</i>.<br>

<span class="breadcrumbs">
[<a href="papers/voynich_latech.pdf" target="_blank">paper</a>]
[<a href="javascript:exp_coll('abstract3');">abstract</a>]
[<a href="javascript:exp_coll('bib3');">bib</a>]
[<a href="slides/voynich_latex_slides.pdf" target="_blank">slides</a>]
</span>

<div id="abstract3" style="display:none">
  <blockquote>
  <h4>Abstract</h4><p>
The Voynich Manuscript is an undeciphered document from medieval Europe. We present current knowledge about the manuscript's text through a series of questions about its linguistic properties. 
</blockquote>
</div>

<div id="bib3" style="display:none">
   <blockquote>
  <h4>.bib</h4><p>
  <pre>
@inproceedings{ReddyKnight:2011b,
  title = {What We Know About The {V}oynich {M}anuscript},
  author = {Sravana Reddy and Kevin Knight},
  booktitle = {ACL Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities},
  year = {2011},
}
</pre>
   </blockquote>
</div>


</p>

<li>
<p>
Sravana Reddy and <a href="http://hum.uchicago.edu/~jagoldsm/Webpage/index.html" target="_blank">John Goldsmith</a>.
(2010). 
<u>An MDL-based Approach to Extracting Subword Units for Grapheme-to-Phoneme Conversion</u>.
In <i>Proceedings of NAACL</i>. <br>

<span class="breadcrumbs">
[<a href="papers/mdlg2p_naacl.pdf" target="_blank">paper</a>]
[<a href="javascript:exp_coll('abstract4');">abstract</a>]
[<a href="javascript:exp_coll('bib4');">bib</a>]
</span>

<div id="abstract4" style="display:none">
  <blockquote>
  <h4>Abstract</h4><p>
We address a key problem in grapheme-to-phoneme conversion: the ambiguity in mapping grapheme units to phonemes. Rather than using single letters and phonemes as units, we propose learning chunks, or subwords, to reduce ambiguity. This can be interpreted as learning a lexicon of subwords that has minimum description length. We implement an algorithm to build such a lexicon, as well as a simple decoder that uses these subwords.
</blockquote>
</div>

<div id="bib4" style="display:none">
   <blockquote>
   <h4>.bib</h4><p>
  <pre>
@inproceedings{ReddyGoldsmith:2010,
  title = {An {MDL}-based Approach to Extracting Subword Units for Grapheme-to-Phoneme Conversion},
  author = {Sravana Reddy and John Goldsmith},
  booktitle = {NAACL},
  year = {2010},
}
</pre>
   </blockquote>
</div>
</p> 

<li>
<p>
Sravana Reddy and <a href="http://people.cs.uchicago.edu/~wax" target="_blank">Sonjia Waxmonsky</a>
(2009). 
<u>Substring-based Transliteration with Conditional Random Fields</u>.
In <i>Proceedings of the ACL Named Entities Workshop (Shared Task)</i>.<br>

<span class="breadcrumbs">
[<a href="papers/crftranslit_news.pdf" target="_blank">paper</a>]
[<a href="javascript:exp_coll('abstract2');">abstract</a>]
[<a href="javascript:exp_coll('bib2');">bib</a>]
</span>

<div id="abstract2" style="display:none">
  <blockquote>
  <h4>Abstract</h4><p>
Motivated by phrase-based translation research, we present a transliteration system where characters are grouped into substrings to be mapped atomically into the target language. We show how this substring representation can be incorporated into a Conditional Random Field model that uses local context and phonemic information. Our training and test data consists of three sets: English to Hindi, English to Kannada, and English to Tamil (Kumaran and Kellner, 2007) – from the 
NEWS 2009 Machine Transliteration Shared Task (Li et al., 2009). 
</blockquote>
</div>

<div id="bib2" style="display:none">
   <blockquote>
   <h4>.bib</h4><p>
  <pre>
@inproceedings{ReddyWaxmonsky:2009b,
  title = {Substring-based Transliteration with Conditional Random Fields},
  author = {Sravana Reddy and Sonjia Waxmonsky},
  booktitle = {ACL Named Entities Workshop},
  year = {2009},
}
</pre>
   </blockquote>
  </div>
  
</p>

  <li>
<p>
Sravana Reddy
  (2009). 
<u>Understanding Eggcorns</u>.
In <i>Proceedings of the NAACL Workshop on Computational Approaches to Linguistic Creativity</i>.<br>

  <span class="breadcrumbs">
[<a href="papers/eggcorns_calc.pdf" target="_blank">paper</a>]
  [<a href="javascript:exp_coll('abstract1');">abstract</a>]
  [<a href="javascript:exp_coll('bib1');">bib</a>]
</span>
  
<div id="abstract1" style="display:none">
  <blockquote>
  <h4>Abstract</h4><p>
An eggcorn is a type of linguistic error where a word is substituted with one that is semantically plausible – that is, the substitution is a semantic reanalysis of what may be a rare, archaic, or otherwise opaque term. We build a system that, given the original word and its eggcorn form, finds a semantic path between the two. Based on these paths, we derive a typology that reflects the different classes of semantic reinterpretation underlying eggcorns.
</blockquote>
</div>

<div id="bib1" style="display:none">
   <blockquote>
   <h4>.bib</h4><p>
  <pre>
@inproceedings{Reddy:2009a,
  title = {Understanding Eggcorns},
  author = {Sravana Reddy},
  booktitle = {NAACL Workshop on Computational Approaches to Linguistic Creativity},
  year = {2009},
}
</pre>
   </blockquote>
  </div>
  
</p>

  </ul>


  <h3 id="present">Presentations</h3>
<ul>
    <p><li>Sravana Reddy and <a href="http://www.dartmouth.edu/~jstanford/" target="_blank">James Stanford</a> (2014). <u>Is the Future Almost
  Here? Large-Scale Completely Automated Vowel Extraction of Free
  Speech</u>. In <i>New Ways of Analyzing Variation</i> (NWAV).
  <br>
<span class="breadcrumbs">
  [<a href="javascript:exp_coll('abstract9');">abstract</a>]
[<a href="slides/nwav2014.pdf" target="_blank">slides</a>]
  
  </span>
  <div id="abstract9" style="display:none">
     <blockquote>
    <h4>Abstract</h4><p>
Automatic Speech Recognition (ASR) is reaching farther into everyday
  life through applications like Apple’s Siri. Likewise,
  sociolinguists have been considering new technologies for vowel
  formant extraction, including semi-automated alignment/extraction
  techniques like the Penn Aligner and Forced Alignment Vowel
  Extraction (FAVE). With humans transcribing recordings into
  sentences, these semi-automated methods produce effective
  results. But sociolinguistics may be on the brink of another
  transformative technology: large-scale, completely automated vowel
  extraction without any need for human transcription. It would then
  be possible to quickly extract vowels from virtually limitless hours
  of recordings, such as YouTube, publicly available audio/video
  archives, and even live-streaming video. How far away is this
  transformative moment? In the present study, we apply
  state-of-the-art ASR to a real-world sociolinguistic dataset
  (U.S. Southern Vowel Shift) as a feasibility test.
    </blockquote>
    </div>
</p>
    
<li>Sravana Reddy, James Stanford, and Joy Zhong (2014). <u>A
  Twitter-Based Study of Newly Formed Clippings in American
  English</u>. In the <i>Annual Meeting of the American Dialect
  Society</i> (ADS).
  </ul>
  
<h3 id="theses">Theses</h3>
  <ul>
    <li>
<p>
<u>Learning Pronunciations from Unlabeled Evidence</u>. 
Doctoral Dissertation, The University of Chicago, 2012.<br>
    
    <span class="breadcrumbs">
    [e-mail for copy]
    [<a href="javascript:exp_coll('abstractphd');">abstract</a>] 
[<a href="javascript:exp_coll('bibphd');">bib</a>]
    </span>

<div id="abstractphd" style="display:none">
  <blockquote>
  <h4>Abstract</h4><p>
The pronunciation of a word represented in an alphabetic writing system (such as this one) is relatively transparent -- but a language's sounds change over time and vary across space, while its spellings remain relatively static, resulting in some amount of divergence between the written and spoken forms. The introduction of loanwords and proper names from other languages with different phonologies and scripts further complicates the relationship between orthography and pronunciation. <p>

However, there are sources of information about the sound of a word in addition to spelling. 
This dissertation presents methods for learning pronunciations using three forms of evidence: speech, word origins, and rhymes.<p>

Speech is the most natural source of evidence: a word's pronunciation is usually clarified upon hearing it in a spoken utterance.  In the case of proper names, knowing the linguistic or ethnic origin of the name is often instrumental in determining how it should be pronounced. Rhymes in poems or songs also provide a cue to pronunciation, particularly for inferring the sound of a word at an earlier point in history.<p>

Using extra-orthographic evidence in a computational model necessitates access to data that provides this information in sufficiently large quantities. Collecting annotated data -- speech labeled with the words that it contains, names with their ethnic origins, or poetry with rhyming patterns -- can be extremely difficult and expensive. On the other hand, raw data -- speech recordings, lists of names, archives of poetry -- is available in plenty. The focus of this dissertation is, therefore, on using unlabeled data for pronunciation learning. <p>

There are two facets of 'pronunciation learning' in this work. One is that of converting the written form of a word to its phonemic representation, known as grapheme-to-phoneme conversion. The other is a less fine-grained objective: rather than learning the exact phonemic forms, we aim to discover clusters of words with similar pronunciations.<p>

The first contribution of this dissertation is a model to incorporate untranscribed spoken data, in addition to an existing lexicon of words and their pronunciations, into a grapheme-to-phoneme learner. This approach is found to improve over models that are trained only on a lexicon. The second contribution is an algorithm that models the latent linguistic origins of names as part of  grapheme-to-phoneme conversion. Not only does this method do better than a model without word origin awareness, it also outperforms existing approaches that first classify orthographic words by origin in a supervised manner, and then train language-specific pronunciation models. The final contribution is an unsupervised learner that discovers the rhyme schemes of stanzas of poetry, as well as rhyming relations between words and clusters of words with a common rhyming sound. 
  </blockquote>
</div>

<div id="bibphd" style="display:none">
   <blockquote>
   <h4>.bib</h4><p>
  <pre>
@phdthesis{Reddy:2012,
  title = {Learning Pronunciations from Unlabeled Evidence},
  author = {Sravana Reddy},
  school = {The University of Chicago},
  year = {2012},
}
</pre>
   </blockquote>
  </div>

    <li>
<p>
<u>Part of Speech Induction Using Non-Negative Matrix Factorization</u>. 
Masters' Thesis, The University of Chicago, 2009. <br>
    
    <span class="breadcrumbs">
[e-mail for copy]
    [<a href="javascript:exp_coll('abstractms');">abstract</a>] 
[<a href="javascript:exp_coll('bibms');">bib</a>]
    </span>

<div id="abstractms" style="display:none">
  <blockquote>
  <h4>Abstract</h4><p>
Unsupervised part-of-speech induction involves the discovery of syntactic categories in a text, 
given no additional information other than the text itself. One requirement of an induction 
system is the ability to handle multiple categories for each word, in order to deal with word 
sense ambiguity. We construct an algorithm for unsupervised part-of-speech induction, treating 
the problem as one of soft clustering. The key technical component of the algorithm is the 
application of the recently developed technique of non-negative matrix factorization to the task 
of category discovery, using word contexts and morphology as syntactic cues. 
</blockquote>
</div>

<div id="bibms" style="display:none">
   <blockquote>
   <h4>.bib</h4><p>
  <pre>
@mastersthesis{Reddy:2009,
  title = {Part of Speech Induction Using Non-Negative Matrix Factorization},
  author = {Sravana Reddy},
  school = {The University of Chicago},
  year = {2009},
}
</pre>
   </blockquote>
  </div>

</p>
    </ul>

    <h3 id="press">Press</h3>
    <ul>
      <li><a
    href="http://www.npr.org/blogs/alltechconsidered/2014/01/16/263096375/researchers-are-totes-studying-how-ppl-shorten-words-on-twitter"
    target="_blank">Researchers Are Totes Studying How Ppl Shorten
    Words On Twitter</a> (NPR's all tech considered, Jan 17
    2014)
      <li><a href="http://www.wired.com/dangerroom/2012/12/codes/" target="_blank">7
    Codes You'll Never Ever Break</a> (Wired, Dec 21 2012)
      </ul>

      <!-- Students -->
<h3>Students</h3>
  
      I've worked with some great students at Dartmouth: James Brofos,
      Irene Feng, Steven Nugent, Crystal Ye, Joy Zhong, Alexander
      Welton, and Ian
      Stewart. The last two wrote senior theses
      on <a
      href="http://www.cs.dartmouth.edu/reports/TR2014-754.pdf"
      target="blank">Automated Stylistic Analysis</a>
      and <a
      href="https://books.google.com/books/about/Now_We_Stronger_Than_Ever.html?id=1GOhoAEACAAJ"
      target="blank">
      African American English Syntax on Twitter</a> -- go check them out!

 <!-- Teaching -->
    
<a name="teaching"></a><h2>Teaching</h2>

      <ul>
  
  <li>Language Variation through the Lens of Web Data (Linguistic
  Summer Institute, 2015)

      <li>
      <a
    href="classes/f14compling/">
      Computational Linguistics</a> (Dartmouth College Winter 2013, Fall 2013, Fall 2014)
      </ul>

    I have also TAed many CS courses as a graduate student at Chicago.

      <!--
<h3>Lab Instructor (UChicago)</h3> 

<ul>
<li>Fundamentals of Programming 
(Fall 2011)
<li>Intro to Computer Science
(Fall 2009, Fall 2010) <br>
<li>Intro to Programming for the World Wide Web (Spring 2010)
<li>Distributed Objects (Spring 2009)<br>
</ul>

<h3>Teaching Assistant (UChicago)</h3>

<ul>
  <li><i>AI:</i>
Computational Linguistics, Artifical Intelligence, Computational Biology
  <li><i>Programming:</i>
Intro to Computer Science, 
 Fundamentals of Programming,
Intro to WWW Programming
  <li><i>Other:</i>
Foundations of Software
</ul>
-->

 <a name="edu"></a> <h2>Experience</h2>

<p>I interned in 2010 and 2011 with the natural language group at the USC
<a href="http://www.isi.edu" target="_blank">Information Sciences Institute</a>, where I worked mainly with <a href="http://www.isi.edu/~knight" target="_blank">Kevin Knight</a>, and 2009 with the speech group at 
<a href="http://www.merl.com" target="_blank">Mitsubishi Electric
Research Labs</a> (MERL) under <a
href="http://egouvea.users.sourceforge.net" target="_blank">Evandro
Gouv&ecirc;a</a>.</p>

<p>  In the more distant past, I spent the summer of 2006 at the 
<a href="http://www.perseus.tufts.edu" target="_blank">Perseus Digital Library</a> at Tufts, working on Latin OCR, and 2005 at the CMU
<a href="http://www.ri.cmu.edu" target="_blank"> Robotics
Institute</a>.</p>

<p>Before graduate school, I went to college at  <a
href="http://www.brandeis.edu" target="_blank">Brandeis University</a>,
where I was supported by the Wien Scholarship. I grew up in <a href="http://en.wikipedia.org/wiki/Bangalore" target="_blank">Bangalore</a>.</p>

<!-- Start of StatCounter Code -->
<script type="text/javascript" language="javascript">
var sc_project=2052709; 
var sc_invisible=1; 
var sc_partition=18; 
var sc_security="c224799b"; 
</script>

<script type="text/javascript" language="javascript" src="http://www.statcounter.com/counter/counter.js"></script><noscript><a href="http://www.statcounter.com/" target="_blank"><img  src="http://c19.statcounter.com/counter.php?sc_project=2052709&java=0&security=c224799b&invisible=1" alt="free hit counter script" border="0"></a> </noscript>
<!-- End of StatCounter Code -->

</div>
</body>
</html>
