<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="">
    <meta name="author" content="">
    <link rel="icon" href="http://www.wellesley.edu/sites/default/files/favicon.ico">

    <title>Sravana Reddy</title>

    <!-- Bootstrap core CSS -->
    <link href="bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="homepage.css" rel="stylesheet">

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>

  <body>

    <nav class="navbar navbar-inverse navbar-fixed-top">
      <div class="container">
        <div id="navbar" class="collapse navbar-collapse">
          <ul class="nav navbar-nav">
	    <li role="presentation" class="active"><a href="#research"
      aria-controls="home" role="tab" data-toggle="tab">Research</a></li>
	    <li role="presentation"><a href="#teaching"
      aria-controls="teaching" role="tab" data-toggle="tab">Teaching/Service</a></li>
<li role="presentation"><a href="#misc"
      aria-controls="misc" role="tab" data-toggle="tab">Misc</a></li>          </ul>
        </div><!--/.nav-collapse -->
      </div>
    </nav>

    <div class="container">

      <div class="main">
	<h1>Sravana Reddy <img src="sravana-name.jpg"></h1>
	<address>sravana.reddy at wellesley dot edu</address>
	<p class="lead">I am a Hess Fellow at <a
	href="http://www.wellesley.edu/">Wellesley College</a>
	Computer Science, working on speech
	and natural
	language processing. I got my PhD from the University of
	Chicago, and spent some time at Dartmouth College as a Neukom Fellow.</p>

      <div class="tab-content">
	
      <div role="tabpanel" class="tab-pane active" id="research">
	
	<h2 id="research">Research</h2>
	
	<p>My interests are broad, and include
	unsupervised machine learning,
	pronunciation modeling, and applications of NLP to linguistics and the humanities.</p>
	
	<h3>Publications</h3>

	<!--     PAPER --->

	<p><strong>Toward completely automated vowel extraction: Introducing
	DARLA.</strong>
	Sravana Reddy and <a
  href="http://www.dartmouth.edu/~jstanford/">James N. Stanford</a>. Forthcoming in
	<em>Linguistics Vanguard (2015)</em>.</p>
	<p>
	<a class="btn btn-xs btn-primary" href="papers/vanguard.pdf">preprint</a>
	<a class="btn btn-xs btn-primary" data-toggle="collapse"
	data-target="#absvanguard" aria-expanded="false" role="button">abstract</a>
	</p>
	
      <div id="absvanguard" class="bg-info collapse abstract">
	
Automatic Speech Recognition (ASR) is reaching further and further
  into everyday life with Apple's Siri, Google voice search, automated
  telephone information systems, dictation devices, closed captioning,
  and other applications. Along with such advances in speech
  technology, sociolinguists have been considering new methods for
  alignment and vowel formant extraction, including techniques like
  the Penn Aligner (Yuan and Liberman, 2008) and the FAVE automated
  vowel extraction program (Evanini et al., 2009, Rosenfelder et al.,
  2011). With humans transcribing audio recordings into sen- tences,
  these semi-automated methods can produce effective vowel formant
  measure- ments (Labov et al., 2013). But as the quality of ASR
  improves, sociolinguistics may be on the brink of another
  transformative technology: large-scale, completely automated vowel
  extraction without any need for human transcription. It would then
  be possible to quickly extract vowels from virtually limitless hours
  of recordings, such as YouTube, publicly available audio/video
  archives, and large-scale personal interviews or streaming
  video. How far away is this transformative moment? In this article,
  we introduce a fully automated program called DARLA (short for
  "Dartmouth Linguistic Automation,"
  <a href="http://darla.dartmouth.edu"
  target"_blank">http://darla.dartmouth.edu</a>),
  which automatically generates transcriptions with ASR and extracts vowels using FAVE. Users simply upload an audio recording of speech, and DARLA produces vowel plots, a table of vowel formants, and probabilities of the phonetic environments for each token. In this paper, we describe DARLA and explore its sociolinguistic applications. We test the system on a dataset of the US Southern Shift and compare the results with semi-automated methods.
      </div>

      <!--     PAPER --->

      	<p><strong>A Web Application for Automated Dialect
  Analysis.</strong>
	Sravana Reddy and <a
  href="http://www.dartmouth.edu/~jstanford/">James N. Stanford</a>. In
	<em>Proceedings of NAACL 2015</em>.</p>
	<p>
	<a class="btn btn-xs btn-primary" href="papers/darla_naacl.pdf">paper</a>
	<a class="btn btn-xs btn-primary" data-toggle="collapse"
	data-target="#absdarlanaacl" aria-expanded="false"
      role="button">abstract</a>
	<a class="btn btn-xs btn-primary" href="slides/darla_naacl_poster.pdf">poster</a>
      </p>

          <div id="absdarlanaacl" class="bg-info collapse abstract">
	
Sociolinguists are regularly faced with the task of measuring phonetic
	    features from speech, which involves manually transcribing
	    audio recordings -- a major bottleneck to analyzing large
	    collections of data. We harness automatic speech
	    recognition to build an online end-to-end web application
	    where users upload untranscribed speech collections and
	    receive formant measurements of the vowels in their
	    data. We demonstrate this tool by using it to
	    automatically analyze President Barack Obama’s vowel
	    pronunciations.	  </div>
	    
	  
<!--     PAPER --->
    	<p><strong>Decoding Running Key Ciphers.</strong>
	Sravana Reddy and <a
  href="http://www.isi.edu/~knight">Kevin Knight</a>. In
	<em>Proceedings of ACL 2012</em>.</p>
	<p>
	<a class="btn btn-xs btn-primary" href="papers/runkey_acl.pdf">paper</a>
	<a class="btn btn-xs btn-primary" data-toggle="collapse"
	data-target="#absrunkey" aria-expanded="false"
      role="button">abstract</a>
      </p>

          <div id="absrunkey" class="bg-info collapse abstract">
There has been recent interest in the problem of decoding letter substitution ciphers using techniques inspired by natural language processing. We consider a different type of classical encoding scheme known as the running key cipher, and propose a search solution using Gibbs sampling with a word language model. We evaluate our method on synthetic ciphertexts of different lengths, and find that it outperforms previous work that employs Viterbi 
decoding with character-based models. 
	  </div>

<!-- PAPER -->
	  <p><strong>G2P Conversion of Proper Names Using Word Origin
	  Information.</strong> <a href="http://people.cs.uchicago.edu/~wax">Sonjia Waxmonsky</a> 
	  and Sravana Reddy. In <em>Proceedings of NAACL 2012</em>.
	  </p>
	<p>
	<a class="btn btn-xs btn-primary" href="papers/wordoriging2p_naacl.pdf">paper</a>
	<a class="btn btn-xs btn-primary" data-toggle="collapse"
	data-target="#absg2pword" aria-expanded="false"
      role="button">abstract</a>
	<a class="btn btn-xs btn-primary"
	  href="slides/wordoriging2p_naacl_poster.pdf">poster</a>
	  	<a class="btn btn-xs btn-primary" href="http://people.cs.uchicago.edu/~wax/wordorigin/">data</a>

      </p>

          <div id="absg2pword" class="bg-info collapse abstract">
Motivated by the fact that the pronunciation of a name may be
influenced by its language of origin,  we present methods to improve
pronunciation prediction of proper names using
word origin information. 
We train grapheme-to-phoneme (G2P) models on language-specific data
sets and interpolate the outputs. 
We perform experiments on US personal surnames, a data set where word origin variation
occurs naturally. Our methods can be used with any G2P algorithm that outputs
posterior probabilities of phoneme sequences for a given word.
	  </div>

	  <!-- PAPER -->
	  <p><strong>Learning from Mistakes: Expanding Pronunciation
	  Lexicons Using Word Recognition Errors.</strong> Sravana
	  Reddy and <a href="http://www.cs.cmu.edu/~egouvea/">Evandro Gouv&ecirc;a</a>. In <em>Proceedings of Interspeech 2011</em>.
	  </p>
	<p>
	<a class="btn btn-xs btn-primary" href="papers/lfm_interspeech.pdf">paper</a>
	<a class="btn btn-xs btn-primary" data-toggle="collapse"
	data-target="#abslfm" aria-expanded="false"
      role="button">abstract</a>
	<a class="btn btn-xs btn-primary"
	  href="slides/lfm_interspeech_slides.pdf">slides</a>

      </p>

          <div id="abslfm" class="bg-info collapse abstract">
We introduce the problem of learning pronunciations of out-of-vocabulary words from word recognition mistakes made by an automatic speech recognition (ASR) system. This question is especially relevant in cases where the  ASR engine is a black box -- meaning that the only acoustic cues about the speech data come from the word recognition outputs. This paper presents an expectation maximization approach to inferring pronunciations from ASR word recognition hypotheses, which outperforms pronunciation estimates of a state of the art grapheme-to-phoneme system.	  </div>
	  
      	  <!-- PAPER -->
	  <p><strong>Unsupervised Discovery of Rhyme Schemes.</strong> Sravana
	  Reddy and <a href="http://www.isi.edu/~knight">Kevin Knight</a>. In <em>Proceedings of ACL 2011</em>.
	  </p>
	<p>
	<a class="btn btn-xs btn-primary" href="papers/rhymes_acl.pdf">paper</a>
	<a class="btn btn-xs btn-primary" data-toggle="collapse"
	data-target="#absrhyme" aria-expanded="false"
      role="button">abstract</a>
	<a class="btn btn-xs btn-primary"
href="slides/rhymes_acl_slides.pdf">slides</a>
	<a class="btn btn-xs btn-primary"
href="https://github.com/sravanareddy/rhymedata">data</a>
	<a class="btn btn-xs btn-primary"
href="https://github.com/sravanareddy/rhymediscovery">code</a>


      </p>

          <div id="absrhyme" class="bg-info collapse abstract">
  This paper describes an unsupervised, language-independent model for finding rhyme schemes in poetry, using no prior knowledge about rhyme or pronunciation.	  </div>

      	  <!-- PAPER -->
	  <p><strong>What We Know About The Voynich Manuscript.</strong> Sravana
	  Reddy and <a href="http://www.isi.edu/~knight">Kevin
	  Knight</a>. In <em>Proceedings of the ACL 2011 Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities</em>.
	  </p>
	<p>
	<a class="btn btn-xs btn-primary" href="papers/voynich_latech.pdf">paper</a>
	<a class="btn btn-xs btn-primary" data-toggle="collapse"
	data-target="#absvoynich" aria-expanded="false"
      role="button">abstract</a>
	<a class="btn btn-xs btn-primary"
href="slides/voynich_latech_slides.pdf">slides</a>
<a class="btn btn-xs btn-primary"
href="https://github.com/sravanareddy/deciphervoynich">code and data</a>
 <a class="btn btn-xs btn-primary"
href="http://www.wired.com/2012/12/codes">press</a>

      </p>

  <div id="absvoynich" class="bg-info collapse abstract">
  The Voynich Manuscript is an undeciphered document from medieval
  Europe. We present current knowledge about the manuscript's text
    through a series of questions about its linguistic properties.
  </div>

      	  <!-- PAPER -->
	  <p><strong>An MDL-based Approach to Extracting Subword Units for Grapheme-to-Phoneme Conversion.</strong> Sravana
	  Reddy and <a href="http://people.cs.uchicago.edu/~jagoldsm/">John 
	  Goldsmith</a>. In <em>Proceedings of NAACL 2010</em>.
	  </p>
	<p>
	<a class="btn btn-xs btn-primary" href="papers/mdlg2p_naacl.pdf">paper</a>
	<a class="btn btn-xs btn-primary" data-toggle="collapse"
	data-target="#absmdl" aria-expanded="false"
      role="button">abstract</a>

      </p>

  <div id="absmdl" class="bg-info collapse abstract">
We address a key problem in grapheme-to-phoneme conversion: the ambiguity in mapping grapheme units to phonemes. Rather than using single letters and phonemes as units, we propose learning chunks, or subwords, to reduce ambiguity. This can be interpreted as learning a lexicon of subwords that has minimum description length. We implement an algorithm to build such a lexicon, as well as a simple decoder that uses these subwords.  </div>

      	  <!-- PAPER -->
	  <p><strong>Substring-based Transliteration with Conditional Random Fields.</strong> Sravana
	  Reddy and <a href="http://people.cs.uchicago.edu/~wax">Sonjia 
	  Waxmonsky</a>. In <em>Proceedings of the ACL 2010 Names
	  Entities Workshop</em>.
	  </p>
	<p>
	<a class="btn btn-xs btn-primary" href="papers/crftranslit_news.pdf">paper</a>
	<a class="btn btn-xs btn-primary" data-toggle="collapse"
	data-target="#abscrf" aria-expanded="false"
      role="button">abstract</a>

      </p>

  <div id="abscrf" class="bg-info collapse abstract">
Motivated by phrase-based translation research, we present a transliteration system where characters are grouped into substrings to be mapped atomically into the target language. We show how this substring representation can be incorporated into a Conditional Random Field model that uses local context and phonemic information. Our training and test data consists of three sets: English to Hindi, English to Kannada, and English to Tamil (Kumaran and Kellner, 2007) from the NEWS 2009 Machine Transliteration Shared Task (Li et al., 2009). 
  </div>

      	  <!-- PAPER -->
	  <p><strong>Understanding Eggcorns.</strong> Sravana
	  Reddy. In <em>Proceedings of the the NAACL 2009 Workshop on Computational Approaches to Linguistic Creativity</em>.
	  </p>
	<p>
	<a class="btn btn-xs btn-primary" href="papers/eggcorns_calc.pdf">paper</a>
	<a class="btn btn-xs btn-primary" data-toggle="collapse"
	data-target="#abseggcorn" aria-expanded="false"
      role="button">abstract</a>

      </p>

  <div id="abseggcorn" class="bg-info collapse abstract">
An eggcorn is a type of linguistic error where a word is substituted with one that is semantically plausible -- that is, the substitution is a semantic reanalysis of what may be a rare, archaic, or otherwise opaque term. We build a system that, given the original word and its eggcorn form, finds a semantic path between the two. Based on these paths, we derive a typology that reflects the different classes of semantic reinterpretation underlying eggcorns.
  </div>

 <!-- PAPER -->

  <h3>Presentations</h3>

   <!-- PAPER -->
  <p><strong>Is the Future Almost
  Here? Large-Scale Completely Automated Vowel Extraction of Free
  Speech.</strong> Sravana Reddy and <a href="http://www.dartmouth.edu/~jstanford">James
  N. Stanford</a>. In <em>NWAV 2014</em>.
  </p>
  	<p>
	<a class="btn btn-xs btn-primary" data-toggle="collapse"
	data-target="#absdarlanwav" aria-expanded="false"
  role="button">abstract</a>
  	<a class="btn btn-xs btn-primary" href="slides/darla_nwav_slides.pdf">slides</a>
      </p>

  <div id="absdarlanwav" class="bg-info collapse abstract">
Automatic Speech Recognition (ASR) is reaching farther into everyday
  life through applications like Apple’s Siri. Likewise,
  sociolinguists have been considering new technologies for vowel
  formant extraction, including semi-automated alignment/extraction
  techniques like the Penn Aligner and Forced Alignment Vowel
  Extraction (FAVE). With humans transcribing recordings into
  sentences, these semi-automated methods produce effective
  results. But sociolinguistics may be on the brink of another
  transformative technology: large-scale, completely automated vowel
  extraction without any need for human transcription. It would then
  be possible to quickly extract vowels from virtually limitless hours
  of recordings, such as YouTube, publicly available audio/video
  archives, and even live-streaming video. How far away is this
  transformative moment? In the present study, we apply
  state-of-the-art ASR to a real-world sociolinguistic dataset
  (U.S. Southern Vowel Shift) as a feasibility test.
  </div>

  <!-- PAPER -->
    <p><strong>A
  Twitter-Based Study of Newly Formed Clippings in American
  English.</strong> Sravana Reddy, <a href="http://www.dartmouth.edu/~jstanford">James
  N. Stanford</a>, and Joy Zhong. In <em>ADS 2014</em>.
  </p>
  <p>
  	<a class="btn btn-xs btn-primary" data-toggle="collapse"
	data-target="#absabbrevads" aria-expanded="false"
  role="button">abstract</a>
  	<a class="btn btn-xs btn-primary" href="slides/abbrevs_ads_slides.pdf">slides</a>
<a class="btn btn-xs btn-primary" href="http://www.npr.org/sections/alltechconsidered/2014/01/16/263096375/researchers-are-totes-studying-how-ppl-shorten-words-on-twitter">press</a>
      </p>

  <div id="absabbrevads" class="bg-info collapse abstract">
Following Baclawski (2012), this study uses Twitter to examine newly formed clippings
among younger speakers, including awks (awkward), adorb (adorable), ridic
(ridiculous), hilar (hilarious). We analyzed 94 million tweets from
    334,000 U.S. Twitter users who posted during 2013 (cf. Eisenstein et al. 2010; Bamman et al. 2012). We find
that while women and men both use truncated forms, women are the leaders of the newer,
primarily adjectival forms. These recently coined forms are also more common in tweets
from urban locations. We compare our results to classic principles (Labov 2001),
illustrating how large-scale Twitter analyses can be valuable in American dialectology.  </div>

  <!-- PAPER -->
    <p><strong>A Document Recognition System for Early Modern
    Latin.</strong> Sravana Reddy and <a href="http://www.perseus.tufts.edu/hopper/about/who/gregoryCrane">Gregory
  Crane</a>. In <em>DHCS 2006</em>.
  </p>
  <p>
  	<a class="btn btn-xs btn-primary" data-toggle="collapse"
	data-target="#absperseus" aria-expanded="false"
  role="button">abstract</a>
      </p>

  <div id="absperseus" class="bg-info collapse abstract">
Large-scale digitization of manuscripts is facilitated by
    high-accuracy optical character recognition (OCR) engines. The
    focus of our work is on using these tools to digitize Latin
    texts. Many of the texts in the language, especially the early
    modern, make heavy use of special characters like ligatures and
    accented abbreviations. Current OCRs are inadequate for our
    purpose: their built-in training sets do not include all these
    special characters, and further, post-processing of OCR output is
    based on data and methods specific to the domain language, most of
    the current systems do not implement error-correction tools for
    Latin. This abstract outlines the development of a document
    recognition system for medieval and early modern Latin texts. We
    first evaluate the performance of the open source OCR framework,
    Gamera, on these manuscripts. We then incorporate language
    modeling functions to sharpen the character recognition output.
  </div>

  <h3>Theses</h3>
  <!--     PAPER --->
    	<p><strong>Learning Pronunciations from Unlabeled Evidence.</strong>
2012. Doctoral Dissertation, 
	<em>The University of Chicago</em>.</p>
 <p>
  	<a class="btn btn-xs btn-primary"
  href="papers/phd_frontmatter.pdf">front matter</a>
      </p>

    <!--     PAPER --->
    	<p><strong>Part of Speech Induction Using Non-negative Matrix  
Factorization.</strong>
2009. Masters' Thesis, 
	<em>The University of Chicago</em>.</p>
 <p>
  	<a class="btn btn-xs btn-primary" data-toggle="collapse"
	data-target="#absms" aria-expanded="false"
  role="button">abstract</a>
  </p>
  
  <div id="absms" class="bg-info collapse abstract">
  Unsupervised part-of-speech induction involves the discovery of  
syntactic categories in a text, given no additional information other  
than the text itself.  One requirement of an induction system is the  
ability to handle multiple categories for each word, in order to deal  
with word sense ambiguity.  We construct an algorithm for unsupervised  
part-of-speech induction, treating the problem as one of soft  
clustering.  The key technical component of the algorithm is the  
application of the recently developed technique of non-negative matrix  
factorization to the task of category discovery, using word contexts  
and morphology as syntactic cues.
  </div>

  </div><!-- /.researchtab -->

        <div role="tabpanel" class="tab-pane" id="teaching">

	  <h2>Teaching/Service</h2>

	  <h3>Courses</h3>
	  <p>I am teaching <a
	  href="http://cs.wellesley.edu/~cs111/">Computer Programming
	  and Problem Solving</a> at Wellesley in Fall 2015.</p>

<h4>Previously:</h3>
<ul>
	  <li>A two week seminar on Language Variation through
  the Lens of Web Data at the LSA 2015 <a href="https://lsa2015.uchicago.edu">Linguistic Summer Institute</a>.

	  <li>At Dartmouth, three iterations of <a
    href="https://piazza.com/dartmouth/fall2014/ling50cosc73/resources">
	  Computational Linguistics</a>, cross-listed with Linguistics
    and Computer Science, in Winter 2013, Fall 2013, and Fall 2014.

	  <li>TA for several courses at
	  Chicago, running the gamut from AI to systems to labs for
	  introductory programming.
</ul>

	  <h3>Students</h3>
<p>	  I've worked with some great students at Dartmouth: James Brofos,
      Irene Feng, Steven Nugent, Crystal Ye, Joy Zhong, Alexander
      Welton, and Ian
      Stewart. The last two wrote senior theses
      on <a
      href="http://www.cs.dartmouth.edu/reports/TR2014-754.pdf"
      target="blank">Automated Stylistic Analysis</a>
      and <a
      href="https://books.google.com/books/about/Now_We_Stronger_Than_Ever.html\
?id=1GOhoAEACAAJ"
      target="blank">
      African American English Syntax on Twitter</a> -- go check them
	  out!</p>

	  <h3>Admin</h3>
<p>	  I was the local organizer for the <a href="http://www.cs.dartmouth.edu/~naclo">NACLO</a>, the North American
	  Computational Linguistics Olympiad, at Dartmouth.</p>

<p>I'm one of the co-chairs of the demo session at <a href="http://naacl.org/naacl-hlt-2016">NAACL 2016</a>. (Submit your papers and pass the CFP around.)</p>

	</div>  <!-- /.teachingtab -->

	<div role="tabpanel" class="tab-pane" id="misc">

	  <h2>Miscellany</h2>

	  <h3>Experience</h3>
	  <p>I interned in 2010 and 2011 with the natural language group at the USC
<a href="http://www.isi.edu" target="_blank">Information Sciences Institute</a>, and 2009 with the speech group at
<a href="http://www.merl.com">Mitsubishi Electric
Research Labs</a> (MERL). In the more distant past, I spent the summer of 2006 at the
<a href="http://www.perseus.tufts.edu">Perseus Digital Library</a> at Tufts, working on Latin OCR, and 2005 at the CMU
<a href="http://www.ri.cmu.edu"> Robotics
Institute</a>.</p>

<p>Before graduate school, I went to college at  <a
href="http://www.brandeis.edu" target="_blank">Brandeis University</a>,
where I was supported by a Wien Scholarship. I grew up in <a href="http://en.\
wikipedia.org/wiki/Bangalore" target="_blank">Bangalore</a>.</p>

	</div> <!--/.misctab -->
	
</div><!-- /.tab -->
  
  </div><!-- /.container -->

<!-- Start of StatCounter Code -->
<script type="text/javascript" language="javascript">
var sc_project=2052709; 
var sc_invisible=1; 
var sc_partition=18; 
var sc_security="c224799b"; 
</script>

<script type="text/javascript" language="javascript" src="http://www.statcounter.com/counter/counter.js"></script><noscript><a href="http://www.statcounter.com/" target="_blank"><img  src="http://c19.statcounter.com/counter.php?sc_project=2052709&java=0&security=c224799b&invisible=1" alt="free hit counter script" border="0"></a> </noscript>
<!-- End of StatCounter Code -->

    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="bootstrap/js/bootstrap.min.js"></script>
    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <script src="bootstrap/js/ie10-viewport-bug-workaround.js"></script>
  </body>
</html>
