<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Sravana Reddy</title>

    <!-- Bootstrap core CSS -->
    <link href="bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="homepage.css" rel="stylesheet">

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>

  <body>

    <nav class="navbar navbar-inverse navbar-fixed-top">
      <div class="container">

        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
                 <span class="sr-only">Toggle navigation</span>
                 <span class="icon-bar"></span>
                 <span class="icon-bar"></span>
                 <span class="icon-bar"></span>
               </button>
        </div>

        <div id="navbar" class="collapse navbar-collapse">
          <ul class="nav navbar-nav">
	    <li role="presentation" class="active"><a href="#research"
      aria-controls="research" role="tab" data-toggle="tab">Research</a></li>
	    <li role="presentation"><a href="#teaching"
      aria-controls="teaching" role="tab" data-toggle="tab">Teaching & Service</a></li>
<li role="presentation"><a href="#toolsdata"
      aria-controls="toolsdata" role="tab" data-toggle="tab">Tools & Data</a></li>
       </ul>
        </div><!--/.nav-collapse -->

      </div>
    </nav>

    <div class="container">

      <div class="main">
	<h1>Sravana Reddy <img src="sravana-name.jpg"></h1>
	<address>sravana.reddy at gmail.com</address>
	<p class="lead">I am a researcher at
		<a href="https://www.spotify.com/">Spotify</a> in Boston,
    where I work on projects related to natural language processing
    and machine learning.
</p>

<p class="lead">
     I got my PhD in Computer Science from
     <a href="https://cs.uchicago.edu">the University of Chicago</a>,
     and have spent time at
<a href="https://isi.edu">USC ISI</a>,
  <a href="http://dartmouth.edu">Dartmouth</a> and
  <a href="http://www.wellesley.edu">Wellesley</a>.
</p>

      <div class="tab-content">

      <div role="tabpanel" class="tab-pane active" id="research">

	<h2 id="research">Research</h2>

<p>
I've spent several years studying NLP, speech, machine learning, and linguistics.
Most of my academic research centers around language variation:
both dealing with it in practical systems, and analyzing it using large corpora.
I'm also interested in the applications of computation to literature and writing.
</p>

<p>I developed and maintain <a href="http://darla.dartmouth.edu">DARLA</a>,
  a web application for automating sociophonetics.
</p>

<!--
  <ol class="breadcrumb">
  <li><a href="#pubs">Publications</a></li>
  <li><a href="#pres">Presentations</a></li>
  <li><a href="#theses">Theses</a></li>
  </ol>
-->

  <div id="pubs">
	<h3>Publications</h3>

  <!--     PAPER --->
  <p id="modelaihmm">
    <strong>Implementing a Hidden Markov Model Toolkit.</strong>
	Sravana Reddy.
In
  <em>Proceedings of the AAAI 2017 Symposium on Educational Advances in Artificial Intelligence (EAAI):
    Model AI Assignments</em>.
</p>
<p>

  <a class="btn btn-xs btn-primary" data-toggle="collapse"
	data-target="#absmodelaihmm" aria-expanded="false" role="button">abstract</a>

  <a class="btn btn-xs btn-warning"
  href="http://modelai.gettysburg.edu/2017/hmm">material</a>

	</p>

      <div id="absmodelaihmm" class="bg-info collapse abstract">
        Hidden Markov Models (HMMs) are a backbone of speech and natural language processing
        (NLP) and computational biology.
        They are a great way to teach general concepts such as dynamic programming,
        data-driven learning and inference, and expectation maximization for
        unsupervised learning.

        We have found that asking students in undergraduate NLP or machine learning
        courses to implement an HMM program is helpful in solidifying these ideas.
        Students also derive a great deal of satisfaction from completing a sizable project.

        However, the algorithms can seem abstract,
        and the scope of the project may be intimidating to some students.
        Our assignment breaks down the HMM into modular chunks, and motivates HMMs
        through applications drawn from NLP research rather than toy problems.
        We include
<ul>
  <li>Starter code in an object-oriented Python framework, and programming guidelines.
<li>Data files that draw from part-of-speech tagging,
  unsupervised discovery of vowels and consonants,
  and decipherment of substitution ciphers.
<li>Lecture slides on HMMs, including step-through visualizations of the
  inference algorithms that translate easily into code.
</ul>
      </div>


	<p id="obfgender">
    <strong>Obfuscating Gender in Social Media Writing.</strong>
	Sravana Reddy and
  <a href="http://www.isi.edu/~knight/">Kevin Knight</a>.
In
  <em>Proceedings of the EMNLP 2016 Workshop on Natural Language Processing and Computational Social Science</em>.
</p>
<p>
<a class="btn btn-xs btn-success"
        href="https://www.aclweb.org/anthology/W/W16/W16-5603.pdf">paper</a>

  <a class="btn btn-xs btn-primary" data-toggle="collapse"
	data-target="#absobfgender" aria-expanded="false" role="button">abstract</a>
	</p>

      <div id="absobfgender" class="bg-info collapse abstract">
The vast availability of textual data on social media has led
algorithms to automatically predict user attributes such as
gender based on the user's writing.
These methods  are valuable for social science research as well as
targeted advertising and profiling,
but also compromise the privacy of users who may not realize that their
personal idiolects can give away their demographic identities.
Can we automatically modify a text so that the author is classified as a
certain target gender, under limited knowledge of the classifier,
while preserving the text's fluency and meaning?
We present a basic model to modify a text using lexical substitution,
show empirical results with Twitter and Yelp data,
and outline ideas for extensions.
</div>

	<!--     PAPER --->

	<p><strong>Toward completely automated vowel extraction: Introducing
	DARLA.</strong>
	Sravana Reddy and
  <a href="http://www.dartmouth.edu/~jstanford/">James N. Stanford</a>.
  <em>Linguistics Vanguard (2015)</em>.</p>
	<p>
	<a class="btn btn-xs btn-success"
	href="papers/vanguard.pdf">preprint</a>
	<a class="btn btn-xs btn-success"
	href="http://www.degruyter.com/view/j/lingvan.ahead-of-print/lingvan-2015-0002/lingvan-2015-0002.xml">paper</a>

	<a class="btn btn-xs btn-primary" data-toggle="collapse"
	data-target="#absvanguard" aria-expanded="false" role="button">abstract</a>
	</p>

      <div id="absvanguard" class="bg-info collapse abstract">

Automatic Speech Recognition (ASR) is reaching further and further
  into everyday life with Apple's Siri, Google voice search, automated
  telephone information systems, dictation devices, closed captioning,
  and other applications. Along with such advances in speech
  technology, sociolinguists have been considering new methods for
  alignment and vowel formant extraction, including techniques like
  the Penn Aligner (Yuan and Liberman, 2008) and the FAVE automated
  vowel extraction program (Evanini et al., 2009, Rosenfelder et al.,
  2011). With humans transcribing audio recordings into sentences,
  these semi-automated methods can produce effective vowel formant
  measurements (Labov et al., 2013). But as the quality of ASR
  improves, sociolinguistics may be on the brink of another
  transformative technology: large-scale, completely automated vowel
  extraction without any need for human transcription. It would then
  be possible to quickly extract vowels from virtually limitless hours
  of recordings, such as YouTube, publicly available audio/video
  archives, and large-scale personal interviews or streaming
  video. How far away is this transformative moment? In this article,
  we introduce a fully automated program called DARLA (short for
  "Dartmouth Linguistic Automation,"
  <a href="http://darla.dartmouth.edu"
  target"_blank">http://darla.dartmouth.edu</a>),
  which automatically generates transcriptions with ASR and extracts vowels using FAVE. Users simply upload an audio recording of speech, and DARLA produces vowel plots, a table of vowel formants, and probabilities of the phonetic environments for each token. In this paper, we describe DARLA and explore its sociolinguistic applications. We test the system on a dataset of the US Southern Shift and compare the results with semi-automated methods.
      </div>

      <!--     PAPER --->

      	<p><strong>A Web Application for Automated Dialect
  Analysis.</strong>
	Sravana Reddy and <a
  href="http://www.dartmouth.edu/~jstanford/">James N. Stanford</a>. In
	<em>Proceedings of NAACL 2015 (Demos)</em>.</p>
	<p>
	<a class="btn btn-xs btn-success" href="http://www.aclweb.org/anthology/N15-3015">paper</a>
	<a class="btn btn-xs btn-primary" data-toggle="collapse"
	data-target="#absdarlanaacl" aria-expanded="false"
      role="button">abstract</a>
	<a class="btn btn-xs btn-primary"
      href="slides/darla_naacl_poster.pdf">poster</a>

      		<a class="btn btn-xs btn-warning"
	href="http://darla.dartmouth.edu">website</a>

      </p>

          <div id="absdarlanaacl" class="bg-info collapse abstract">

Sociolinguists are regularly faced with the task of measuring phonetic
	    features from speech, which involves manually transcribing
	    audio recordings -- a major bottleneck to analyzing large
	    collections of data. We harness automatic speech
	    recognition to build an online end-to-end web application
	    where users upload untranscribed speech collections and
	    receive formant measurements of the vowels in their
	    data. We demonstrate this tool by using it to
	    automatically analyze President Barack Obama’s vowel
	    pronunciations.	  </div>


<!--     PAPER --->
    	<p><strong>Decoding Running Key Ciphers.</strong>
	Sravana Reddy and <a
  href="http://www.isi.edu/~knight">Kevin Knight</a>. In
	<em>Proceedings of ACL 2012</em>.</p>
	<p>
	<a class="btn btn-xs btn-success" href="http://www.aclweb.org/anthology/P12-2016">paper</a>
	<a class="btn btn-xs btn-primary" data-toggle="collapse"
	data-target="#absrunkey" aria-expanded="false"
      role="button">abstract</a>
      </p>

          <div id="absrunkey" class="bg-info collapse abstract">
There has been recent interest in the problem of decoding letter substitution ciphers using techniques inspired by natural language processing. We consider a different type of classical encoding scheme known as the running key cipher, and propose a search solution using Gibbs sampling with a word language model. We evaluate our method on synthetic ciphertexts of different lengths, and find that it outperforms previous work that employs Viterbi
decoding with character-based models.
	  </div>

<!-- PAPER -->
	  <p><strong>G2P Conversion of Proper Names Using Word Origin
	  Information.</strong> <a href="http://people.cs.uchicago.edu/~wax">Sonjia Waxmonsky</a>
	  and Sravana Reddy. In <em>Proceedings of NAACL 2012</em>.
	  </p>
	<p>
	<a class="btn btn-xs btn-success" href="http://aclweb.org/anthology/N/N12/N12-1039.pdf">paper</a>
	<a class="btn btn-xs btn-primary" data-toggle="collapse"
	data-target="#absg2pword" aria-expanded="false"
      role="button">abstract</a>
	<a class="btn btn-xs btn-primary"
	  href="slides/wordoriging2p_naacl_poster.pdf">poster</a>
	  	<a class="btn btn-xs btn-warning" href="http://people.cs.uchicago.edu/~wax/wordorigin/">data</a>

      </p>

          <div id="absg2pword" class="bg-info collapse abstract">
Motivated by the fact that the pronunciation of a name may be
influenced by its language of origin,  we present methods to improve
pronunciation prediction of proper names using
word origin information.
We train grapheme-to-phoneme (G2P) models on language-specific data
sets and interpolate the outputs.
We perform experiments on US personal surnames, a data set where word origin variation
occurs naturally. Our methods can be used with any G2P algorithm that outputs
posterior probabilities of phoneme sequences for a given word.
	  </div>

	  <!-- PAPER -->
	  <p><strong>Learning from Mistakes: Expanding Pronunciation
	  Lexicons Using Word Recognition Errors.</strong> Sravana
	  Reddy and <a href="http://www.cs.cmu.edu/~egouvea/">Evandro Gouv&ecirc;a</a>. In <em>Proceedings of Interspeech 2011</em>.
	  </p>
	<p>
	<a class="btn btn-xs btn-success" href="papers/lfm_interspeech.pdf">paper</a>
	<a class="btn btn-xs btn-primary" data-toggle="collapse"
	data-target="#abslfm" aria-expanded="false"
      role="button">abstract</a>
	<a class="btn btn-xs btn-primary"
	  href="slides/lfm_interspeech_slides.pdf">slides</a>

      </p>

          <div id="abslfm" class="bg-info collapse abstract">
We introduce the problem of learning pronunciations of out-of-vocabulary words from word recognition mistakes made by an automatic speech recognition (ASR) system. This question is especially relevant in cases where the  ASR engine is a black box -- meaning that the only acoustic cues about the speech data come from the word recognition outputs. This paper presents an expectation maximization approach to inferring pronunciations from ASR word recognition hypotheses, which outperforms pronunciation estimates of a state of the art grapheme-to-phoneme system.	  </div>

      	  <!-- PAPER -->
	  <p><strong>Unsupervised Discovery of Rhyme Schemes.</strong> Sravana
	  Reddy and <a href="http://www.isi.edu/~knight">Kevin Knight</a>. In <em>Proceedings of ACL 2011</em>.
	  </p>
	<p>
	<a class="btn btn-xs btn-success" href="http://www.aclweb.org/anthology/P11-2014">paper</a>
	<a class="btn btn-xs btn-primary" data-toggle="collapse"
	data-target="#absrhyme" aria-expanded="false"
      role="button">abstract</a>
	<a class="btn btn-xs btn-primary"
href="slides/rhymes_acl_slides.pdf">slides</a>
	<a class="btn btn-xs btn-warning"
href="https://github.com/sravanareddy/rhymedata">data</a>
	<a class="btn btn-xs btn-warning"
href="https://github.com/sravanareddy/rhymediscovery">code</a>


      </p>

          <div id="absrhyme" class="bg-info collapse abstract">
  This paper describes an unsupervised, language-independent model for finding rhyme schemes in poetry, using no prior knowledge about rhyme or pronunciation.	  </div>

      	  <!-- PAPER -->
	  <p><strong>What We Know About The Voynich Manuscript.</strong> Sravana
	  Reddy and <a href="http://www.isi.edu/~knight">Kevin
	  Knight</a>. In <em>Proceedings of the ACL 2011 Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities</em>.
	  </p>
	<p>
	<a class="btn btn-xs btn-success" href="http://www.aclweb.org/anthology/W11-1511">paper</a>
	<a class="btn btn-xs btn-primary" data-toggle="collapse"
	data-target="#absvoynich" aria-expanded="false"
      role="button">abstract</a>
	<a class="btn btn-xs btn-primary"
href="slides/voynich_latech_slides.pdf">slides</a>
<a class="btn btn-xs btn-warning"
href="https://github.com/sravanareddy/deciphervoynich">code and data</a>
 <a class="btn btn-xs btn-info"
href="http://www.wired.com/2012/12/codes">press</a>

      </p>

  <div id="absvoynich" class="bg-info collapse abstract">
  The Voynich Manuscript is an undeciphered document from medieval
  Europe. We present current knowledge about the manuscript's text
    through a series of questions about its linguistic properties.
  </div>

      	  <!-- PAPER -->
	  <p><strong>An MDL-based Approach to Extracting Subword Units for Grapheme-to-Phoneme Conversion.</strong> Sravana
	  Reddy and <a href="http://people.cs.uchicago.edu/~jagoldsm/">John
	  Goldsmith</a>. In <em>Proceedings of NAACL 2010</em>.
	  </p>
	<p>
	<a class="btn btn-xs btn-success" href="https://aclweb.org/anthology/N/N10/N10-1107.pdf">paper</a>
	<a class="btn btn-xs btn-primary" data-toggle="collapse"
	data-target="#absmdl" aria-expanded="false"
      role="button">abstract</a>

      </p>

  <div id="absmdl" class="bg-info collapse abstract">
We address a key problem in grapheme-to-phoneme conversion: the ambiguity in mapping grapheme units to phonemes. Rather than using single letters and phonemes as units, we propose learning chunks, or subwords, to reduce ambiguity. This can be interpreted as learning a lexicon of subwords that has minimum description length. We implement an algorithm to build such a lexicon, as well as a simple decoder that uses these subwords.  </div>

      	  <!-- PAPER -->
	  <p><strong>Substring-based Transliteration with Conditional Random Fields.</strong> Sravana
	  Reddy and <a href="http://people.cs.uchicago.edu/~wax">Sonjia
	  Waxmonsky</a>. In <em>Proceedings of the ACL 2010 Names
	  Entities Workshop</em>.
	  </p>
	<p>
	<a class="btn btn-xs btn-success" href="http://www.aclweb.org/anthology/W09-3520">paper</a>
	<a class="btn btn-xs btn-primary" data-toggle="collapse"
	data-target="#abscrf" aria-expanded="false"
      role="button">abstract</a>

      </p>

  <div id="abscrf" class="bg-info collapse abstract">
Motivated by phrase-based translation research, we present a transliteration system where characters are grouped into substrings to be mapped atomically into the target language. We show how this substring representation can be incorporated into a Conditional Random Field model that uses local context and phonemic information. Our training and test data consists of three sets: English to Hindi, English to Kannada, and English to Tamil (Kumaran and Kellner, 2007) from the NEWS 2009 Machine Transliteration Shared Task (Li et al., 2009).
  </div>

      	  <!-- PAPER -->
	  <p><strong>Understanding Eggcorns.</strong> Sravana
	  Reddy. In <em>Proceedings of the the NAACL 2009 Workshop on Computational Approaches to Linguistic Creativity</em>.
	  </p>
	<p>
	<a class="btn btn-xs btn-success" href="http://www.aclweb.org/anthology/W09-2003">paper</a>
	<a class="btn btn-xs btn-primary" data-toggle="collapse"
	data-target="#abseggcorn" aria-expanded="false"
      role="button">abstract</a>

      </p>

  <div id="abseggcorn" class="bg-info collapse abstract">
An eggcorn is a type of linguistic error where a word is substituted with one that is semantically plausible -- that is, the substitution is a semantic reanalysis of what may be a rare, archaic, or otherwise opaque term. We build a system that, given the original word and its eggcorn form, finds a semantic path between the two. Based on these paths, we derive a typology that reflects the different classes of semantic reinterpretation underlying eggcorns.
  </div>

</div> <!-- /.pubs -->

<div id="pres">
  <h3>Presentations</h3>

<p>These are non-archival papers at conferences.</p>

<!-- PAPER -->
<p><strong>A large-scale online study of dialect variation in the US Northeast: Crowdsourcing with Amazon Mechanical Turk</strong>.
Chaeyoon Kim, Sravana Reddy, Ezra Wyschogrod, and <a href="http://www.dartmouth.edu/~jstanford">James Stanford</a>.
In <em>NWAV 2016</em>.
        <a class="btn btn-xs btn-primary" data-toggle="collapse"
        data-target="#absmturknwav" aria-expanded="false"
  role="button">abstract</a>
      </p>

  <div id="absmturknwav" class="bg-info collapse abstract">
Due to the Founder Effect and the early English colonies, the US Northeast has some of the smallest dialect sub-regions in North America. Can these fine-grained distinctions be observed in an online crowd-sourced survey? Moreover, Carver predicts that new features emerge along the same lines as previous generations. Is this happening in Eastern New England?
     We used Amazon Mechanical Turk for two online crowdsourcing tasks: a self-reporting survey and an audio-recording task. We analyze the data graphically and statistically and compare with prior work.
</div>

<!-- PAPER -->
   <p><strong>Automatic speech recognition in sociophonetics.</strong>
  Sravana Reddy, <a href="http://www.dartmouth.edu/~jstanford">James
  N. Stanford</a>, and <a
  href="https://sites.google.com/site/lmlefkowitz/home">Michael Lefkowitz</a>.
  Workshop (tutorial) in <em>NWAV 2015</em>.
  <a class="btn btn-xs btn-primary" href="http://linguistics.utoronto.ca/nwav44/workshops.html#dipaolo">link</a>
      </p>

   <!-- PAPER -->
  <p><strong>Is the Future Almost
  Here? Large-Scale Completely Automated Vowel Extraction of Free
  Speech.</strong> Sravana Reddy and <a href="http://www.dartmouth.edu/~jstanford">James
  N. Stanford</a>. In <em>NWAV 2014</em>.
  </p>
  	<p>
	<a class="btn btn-xs btn-primary" data-toggle="collapse"
	data-target="#absdarlanwav" aria-expanded="false"
  role="button">abstract</a>
  	<a class="btn btn-xs btn-primary" href="slides/darla_nwav_slides.pdf">slides</a>
      </p>

  <div id="absdarlanwav" class="bg-info collapse abstract">
Automatic Speech Recognition (ASR) is reaching farther into everyday
  life through applications like Apple’s Siri. Likewise,
  sociolinguists have been considering new technologies for vowel
  formant extraction, including semi-automated alignment/extraction
  techniques like the Penn Aligner and Forced Alignment Vowel
  Extraction (FAVE). With humans transcribing recordings into
  sentences, these semi-automated methods produce effective
  results. But sociolinguistics may be on the brink of another
  transformative technology: large-scale, completely automated vowel
  extraction without any need for human transcription. It would then
  be possible to quickly extract vowels from virtually limitless hours
  of recordings, such as YouTube, publicly available audio/video
  archives, and even live-streaming video. How far away is this
  transformative moment? In the present study, we apply
  state-of-the-art ASR to a real-world sociolinguistic dataset
  (U.S. Southern Vowel Shift) as a feasibility test.
  </div>

  <!-- PAPER -->
    <p><strong>A
  Twitter-Based Study of Newly Formed Clippings in American
  English.</strong> Sravana Reddy, <a href="http://www.dartmouth.edu/~jstanford">James
  N. Stanford</a>, and Joy Zhong. In <em>ADS 2014</em>.
  </p>
  <p>
  	<a class="btn btn-xs btn-primary" data-toggle="collapse"
	data-target="#absabbrevads" aria-expanded="false"
  role="button">abstract</a>
  	<a class="btn btn-xs btn-primary" href="slides/abbrevs_ads_slides.pdf">slides</a>
<a class="btn btn-xs btn-info" href="http://www.npr.org/sections/alltechconsidered/2014/01/16/263096375/researchers-are-totes-studying-how-ppl-shorten-words-on-twitter">press</a>
      </p>

  <div id="absabbrevads" class="bg-info collapse abstract">
Following Baclawski (2012), this study uses Twitter to examine newly formed clippings
among younger speakers, including awks (awkward), adorb (adorable), ridic
(ridiculous), hilar (hilarious). We analyzed 94 million tweets from
    334,000 U.S. Twitter users who posted during 2013 (cf. Eisenstein et al. 2010; Bamman et al. 2012). We find
that while women and men both use truncated forms, women are the leaders of the newer,
primarily adjectival forms. These recently coined forms are also more common in tweets
from urban locations. We compare our results to classic principles (Labov 2001),
illustrating how large-scale Twitter analyses can be valuable in American dialectology.  </div>

  <!-- PAPER -->
    <p><strong>A Document Recognition System for Early Modern
    Latin.</strong> Sravana Reddy and <a href="http://www.perseus.tufts.edu/hopper/about/who/gregoryCrane">Gregory
  Crane</a>. In <em>DHCS 2006</em>.
    	<a class="btn btn-xs btn-primary" data-toggle="collapse"
	data-target="#absperseus" aria-expanded="false"
  role="button">abstract</a>
      </p>

  <div id="absperseus" class="bg-info collapse abstract">
Large-scale digitization of manuscripts is facilitated by
    high-accuracy optical character recognition (OCR) engines. The
    focus of our work is on using these tools to digitize Latin
    texts. Many of the texts in the language, especially the early
    modern, make heavy use of special characters like ligatures and
    accented abbreviations. Current OCRs are inadequate for our
    purpose: their built-in training sets do not include all these
    special characters, and further, post-processing of OCR output is
    based on data and methods specific to the domain language, most of
    the current systems do not implement error-correction tools for
    Latin. This abstract outlines the development of a document
    recognition system for medieval and early modern Latin texts. We
    first evaluate the performance of the open source OCR framework,
    Gamera, on these manuscripts. We then incorporate language
    modeling functions to sharpen the character recognition output.
  </div>

</div> <!-- /.pres -->

<div id="theses">
  <h3>Theses</h3>
  <!--     PAPER --->
    	<p><strong>Learning Pronunciations from Unlabeled Evidence.</strong>
2012. Doctoral Dissertation,
	<em>The University of Chicago</em>.
  	<a class="btn btn-xs btn-primary"
  href="papers/phd_frontmatter.pdf">front matter</a>
      </p>

    <!--     PAPER --->
    	<p><strong>Part of Speech Induction Using Non-negative Matrix
Factorization.</strong>
2009. Masters' Thesis,
	<em>The University of Chicago</em>.
   	<a class="btn btn-xs btn-primary" data-toggle="collapse"
	data-target="#absms" aria-expanded="false"
  role="button">abstract</a>
  </p>

  <div id="absms" class="bg-info collapse abstract">
  Unsupervised part-of-speech induction involves the discovery of
syntactic categories in a text, given no additional information other
than the text itself.  One requirement of an induction system is the
ability to handle multiple categories for each word, in order to deal
with word sense ambiguity.  We construct an algorithm for unsupervised
part-of-speech induction, treating the problem as one of soft
clustering.  The key technical component of the algorithm is the
application of the recently developed technique of non-negative matrix
factorization to the task of category discovery, using word contexts
and morphology as syntactic cues.
  </div>

</div><!-- /.theses -->

<div id="students">
  <h3>Students Advised</h3>

<p>
<a href="http://ianbstewart.github.io">Ian Stewart</a> (Senior Thesis at Dartmouth).
    Now a PhD student at Georgia Tech.

    <ul>
      <li>
  Now We Stronger Than Ever: African-American Syntax in Twitter</a>.
  In <em>Proceedings of the Student Research Workshop at EACL 2014</em>.
   <a class="btn btn-xs btn-success" href="http://www.aclweb.org/anthology/E14-3004">paper</a>
</ul>
</p>

<p>
<a href="https://www.linkedin.com/in/emily-ahn-50205472/">Emily Ahn</a>
(Senior Thesis at Wellesley).
Now a student at Carnegie Mellon LTI.

<ul>
  <li>
A Computational Approach to Foreign Accent Classification. <a class="btn btn-xs btn-success" href="http://repository.wellesley.edu/thesiscollection/323/">thesis</a>
</ul>
</p>

</div>  <!-- /.students -->

  </div><!-- /.researchtab -->

        <div role="tabpanel" class="tab-pane" id="teaching">

	  <h2>Teaching & Service</h2>

	 <ul>
     <li><a href="http://wellesleynlp.github.io/machinelearning/index.html">Machine Learning</a>, Wellesley (Spring 2017)
    <li> <a
	  href="http://cs111.wellesley.edu/">Computer Programming
	  and Problem Solving</a>, Wellesley (Fall 2016, Fall 2015)
<li><a href="http://wellesleynlp.github.io/spring16/">Natural Language Processing</a>, Wellelsey (Spring 2016)
	  <li>A two week seminar on Language Variation through
  the Lens of Web Data at the LSA 2015 <a href="https://lsa2015.uchicago.edu">Linguistic Summer Institute</a>.

	  <li>At Dartmouth, three iterations of
	  Computational Linguistics</a>, cross-listed with Linguistics
    and Computer Science, in <a href="https://piazza.com/dartmouth/winter2013/ling50cosc9/home">Winter 2013</a>, <a href="https://piazza.com/dartmouth/fall2013/ling50cosc73/home">Fall 2013</a>, and Fall 2014.
</ul>

<p>	  I was the local organizer for the North American
    Computational Linguistics Olympiad (<a href="http://www.cs.dartmouth.edu/~naclo">NACLO</a>) at Dartmouth,
and one of the co-chairs of the demo session at <a href="http://naacl.org/naacl-hlt-2016/demos.html">NAACL 2016</a>.
I also review for *ACL conferences and workshops, and various journals.
</p>

<p>I organized the <a href="http://cs.wellesley.edu/~colloquium">Wellesley CS Colloquium</a> in my last year.
</p>

	</div>  <!-- /.teachingtab -->

  <div role="tabpanel" class="tab-pane" id="toolsdata">
  <h2 id="toolsdata">Tools and Data</h2>

<p>
This is a collection of various resources I collected/created for my work
that may be useful.
</p>

<!-- PAPER -->
<p><strong>Python Autograder with HTML Output</strong> (under development).
Sravana Reddy and <a href="https://www.linkedin.com/in/daniela-kreimerman-arroyo-6a484b101">Daniela Kreimerman</a>. 2016.<br>
Autograder for the Introductory CS class at Wellesley.
</p>
<p>
<a class="btn btn-xs btn-warning" href="https://github.com/wellesleycs111/autograder">code</a>
</p>

  <!-- PAPER -->
<p><strong>Transcriptions for the
  CSLU Foreign-Accented English Corpus.</strong>
  <a href="https://www.linkedin.com/in/emily-ahn-50205472">Emily Ahn</a>
 and Sravana Reddy. 2016.<br>
The CSLU Foreign-Accented Speech Corpus is a great source of speech data
from non-native English speakers.
We crowdsourced transcriptions for 7 of the 23 native languages on Mechanical Turk,
and are making them available here.
</p>
<p><a class="btn btn-xs btn-warning" href="https://github.com/wellesleynlp/cslutrans">data</a></p>

<!-- PAPER -->
<p><strong>DARLA (Dartmouth Linguistic Automation).</strong>
  Sravana Reddy and
  <a href="http://www.dartmouth.edu/~jstanford/">James Stanford</a>,
with assistance from <a href="http://irenefeng.com">Irene Feng</a>. 2015-2016.<br>
DARLA is a suite of automated analysis programs tailored to
research questions in sociophonetics.
</p>
<p>
<a class="btn btn-xs btn-warning" href="http://darla.dartmouth.edu">website</a>
<span class="btn btn-xs btn-default">code available on request</span>
</p>

<!-- PAPER -->
<p><strong>Chicago Rhyming Poetry Corpus.</strong>
  <a href="http://people.linguistics.mcgill.ca/~morgan/">Morgan Sonderegger</a>
  and Sravana Reddy. 2011.<br>
A collection of rhyming poetry in English and French, manually annotated with rhyme schemes.
</p>
<p>
<a class="btn btn-xs btn-warning" href="https://github.com/sravanareddy/rhymedata">data</a>
</p>

	</div>  <!-- /.toolstab -->

</div><!-- /.tab -->

</div>  <!-- ./main -->
  </div><!-- /.container -->

<!-- Start of StatCounter Code -->
<script type="text/javascript" language="javascript">
var sc_project=2052709;
var sc_invisible=1;
var sc_partition=18;
var sc_security="c224799b";
</script>

<script type="text/javascript" language="javascript" src="http://www.statcounter.com/counter/counter.js"></script><noscript><a href="http://www.statcounter.com/" target="_blank"><img  src="http://c19.statcounter.com/counter.php?sc_project=2052709&java=0&security=c224799b&invisible=1" alt="free hit counter script" border="0"></a> </noscript>
<!-- End of StatCounter Code -->

    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="bootstrap/js/bootstrap.min.js"></script>
    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <script src="bootstrap/js/ie10-viewport-bug-workaround.js"></script>
  </body>
</html>
